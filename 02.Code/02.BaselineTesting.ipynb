{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import sys\n",
    "module_path = \"../src\"\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "from utils.utils import seed_everything\n",
    "from utils.scaler import DataScaler\n",
    "from models.trainer import Trainer\n",
    "from models.lstm import Model_LSTM\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import wandb\n",
    "DATA_PATH = '../01.Data'\n",
    "DEBUG = False\n",
    "os.environ['WANDB_SILENT']=\"True\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\ntrain_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'),nrows=80*100)\\nif DEBUG:\\n    train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'),nrows=80*100)\\nelse:\\n    train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'))    \\ntest_df  = pd.read_csv(os.path.join(DATA_PATH,'test.csv'))\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "%%time\n",
    "train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'),nrows=80*100)\n",
    "if DEBUG:\n",
    "    train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'),nrows=80*100)\n",
    "else:\n",
    "    train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'))    \n",
    "test_df  = pd.read_csv(os.path.join(DATA_PATH,'test.csv'))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feat_eng(df):\n",
    "    # Add Feature engineering df:\n",
    "    df['area'] = df['time_step'] * df['u_in']\n",
    "    df['area'] = df.groupby('breath_id')['area'].cumsum()\n",
    "    \n",
    "    df['u_in_cumsum'] = (df['u_in']).groupby(df['breath_id']).cumsum()\n",
    "    \n",
    "    df['u_in_lag1'] = df.groupby('breath_id')['u_in'].shift(1)\n",
    "    df['u_out_lag1'] = df.groupby('breath_id')['u_out'].shift(1)\n",
    "    df['u_in_lag_back1'] = df.groupby('breath_id')['u_in'].shift(-1)\n",
    "    df['u_out_lag_back1'] = df.groupby('breath_id')['u_out'].shift(-1)\n",
    "    df['u_in_lag2'] = df.groupby('breath_id')['u_in'].shift(2)\n",
    "    df['u_out_lag2'] = df.groupby('breath_id')['u_out'].shift(2)\n",
    "    df['u_in_lag_back2'] = df.groupby('breath_id')['u_in'].shift(-2)\n",
    "    df['u_out_lag_back2'] = df.groupby('breath_id')['u_out'].shift(-2)\n",
    "    df['u_in_lag3'] = df.groupby('breath_id')['u_in'].shift(3)\n",
    "    df['u_out_lag3'] = df.groupby('breath_id')['u_out'].shift(3)\n",
    "    df['u_in_lag_back3'] = df.groupby('breath_id')['u_in'].shift(-3)\n",
    "    df['u_out_lag_back3'] = df.groupby('breath_id')['u_out'].shift(-3)\n",
    "    df['u_in_lag4'] = df.groupby('breath_id')['u_in'].shift(4)\n",
    "    df['u_out_lag4'] = df.groupby('breath_id')['u_out'].shift(4)\n",
    "    df['u_in_lag_back4'] = df.groupby('breath_id')['u_in'].shift(-4)\n",
    "    df['u_out_lag_back4'] = df.groupby('breath_id')['u_out'].shift(-4)\n",
    "    df = df.fillna(0)\n",
    "    \n",
    "    df['breath_id__u_in__max'] = df.groupby(['breath_id'])['u_in'].transform('max')\n",
    "    df['breath_id__u_out__max'] = df.groupby(['breath_id'])['u_out'].transform('max')\n",
    "    \n",
    "    df['u_in_diff1'] = df['u_in'] - df['u_in_lag1']\n",
    "    df['u_out_diff1'] = df['u_out'] - df['u_out_lag1']\n",
    "    df['u_in_diff2'] = df['u_in'] - df['u_in_lag2']\n",
    "    df['u_out_diff2'] = df['u_out'] - df['u_out_lag2']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['breath_id__u_in__diffmax'] = df.groupby(['breath_id'])['u_in'].transform('max') - df['u_in']\n",
    "    df['breath_id__u_in__diffmean'] = df.groupby(['breath_id'])['u_in'].transform('mean') - df['u_in']\n",
    "    \n",
    "    df['u_in_diff3'] = df['u_in'] - df['u_in_lag3']\n",
    "    df['u_out_diff3'] = df['u_out'] - df['u_out_lag3']\n",
    "    df['u_in_diff4'] = df['u_in'] - df['u_in_lag4']\n",
    "    df['u_out_diff4'] = df['u_out'] - df['u_out_lag4']\n",
    "    df['cross']= df['u_in']*df['u_out']\n",
    "    df['cross2']= df['time_step']*df['u_out']\n",
    "    \n",
    "    df['R'] = df['R'].astype(str)\n",
    "    df['C'] = df['C'].astype(str)\n",
    "    df['R__C'] = df[\"R\"].astype(str) + '__' + df[\"C\"].astype(str)\n",
    "    df = pd.get_dummies(df)\n",
    "    return df    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_fn(train,valid,cfg):\n",
    "    # Call seed\n",
    "    seed_everything(cfg.seed)\n",
    "    model    = Model_LSTM(cfg)\n",
    "    trainer  = Trainer(config = cfg,model = model)\n",
    "    best_val_loss = trainer.fit(train,valid)\n",
    "    print(f'Best Val Loss: {best_val_loss}')\n",
    "    return trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_mae_filtered(df,target = 'pressure',preds = 'oof'):\n",
    "    metric_df  = df[df['u_out']!=1].reset_index(drop = True)\n",
    "    mae_metric = mean_absolute_error(metric_df[target].values,metric_df[preds].values)\n",
    "    del metric_df\n",
    "    return mae_metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_kfold():\n",
    "    cfg       = Config()\n",
    "    run_folds = cfg.run_folds \n",
    "    if DEBUG:\n",
    "        train_df = pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv'),nrows=80*100)\n",
    "        test_df  = pd.read_csv(os.path.join(DATA_PATH,'test.csv'),nrows=80*100)\n",
    "    else:\n",
    "        train_df = feat_eng(pd.read_csv(os.path.join(DATA_PATH,'train_folds.csv')))   \n",
    "        test_df  = feat_eng(pd.read_csv(os.path.join(DATA_PATH,'test.csv')))\n",
    "    test_df['pressure'] = -1\n",
    "    cfg.cols       = train_df.drop(columns = ['id','breath_id','pressure','u_out','fold']).columns.to_list()\n",
    "    cfg.input_size = len(cfg.cols)\n",
    "    # Scaling Dataset\n",
    "    scaler   = DataScaler(train_df,sc_name = cfg.sc_name,cols = cfg.cols)\n",
    "    train_df = scaler.transform(train_df)\n",
    "    test_df  = scaler.transform(test_df)\n",
    "    # Data to store\n",
    "    preds_kfold = 0\n",
    "    train_df.loc[:,'oof'] = -1\n",
    "    for fold in run_folds:\n",
    "        print(f\"***********************************************\")\n",
    "        print(f\"**************** FOLD : {fold} *********************\")\n",
    "        print(f\"***********************************************\")\n",
    "        cfg.fold        = fold\n",
    "        cfg.output_path = os.path.join(cfg.output_dir,cfg.experiment_name,f'fold_{fold}')\n",
    "        # Training Dataset\n",
    "        train     = train_df[train_df['fold']!=fold].reset_index(drop = True)\n",
    "        # Valid Dataset\n",
    "        valid     = train_df[train_df['fold']==fold]\n",
    "        valid_index = valid.index.to_list()\n",
    "        valid     = valid.reset_index(drop = True)\n",
    "        # Trainer Part\n",
    "        trainer   = train_fn(train,valid,cfg)\n",
    "        # Valid Preds:\n",
    "        _, valid_preds = trainer.predict(valid,os.path.join(cfg.output_path,'model.pt'))\n",
    "        valid['oof'] = valid_preds.reshape(-1) \n",
    "        print('Valid Metric: ',compute_mae_filtered(valid[['pressure','u_out','oof']]))\n",
    "        train_df.loc[valid_index,'oof'] = valid_preds.reshape(-1)\n",
    "        if fold == run_folds[-1]:\n",
    "            oof_metric = compute_mae_filtered(train_df[['pressure','u_out','oof']])\n",
    "            trainer._log({'oof_metric':oof_metric})\n",
    "        # Test Preds\n",
    "        _, test_preds = trainer.predict(test_df,os.path.join(cfg.output_path,'model.pt'))\n",
    "        preds_kfold   += test_preds\n",
    "        if fold != run_folds[-1]:\n",
    "            del trainer\n",
    "        del train,valid\n",
    "        \n",
    "    # Saving test preds\n",
    "    test_df['preds'] = preds_kfold.reshape(-1)\n",
    "    test_df[['id','breath_id','preds']].to_csv(os.path.join(cfg.output_dir,cfg.experiment_name,f'test_preds.csv'),index = False) \n",
    "    trainer._upload_df(name = 'preds', data = test_df[['id','breath_id','preds']])\n",
    "    # Saving oof predictions\n",
    "    train_df[['id','breath_id','oof']].to_csv(os.path.join(cfg.output_dir,cfg.experiment_name,f'oof_preds.csv'),index = False)\n",
    "    trainer._upload_df(name = 'oof_train', data = train_df[['id','breath_id','oof']])\n",
    "    trainer._finish()\n",
    "    del trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config():\n",
    "    # =========== General Parameters ========\n",
    "    seed = 42\n",
    "    logging = True\n",
    "    run_folds       = [0,1,2,3,4]\n",
    "    # ======== Model Parameters =============\n",
    "    input_size  = -1\n",
    "    hidden_size = 300\n",
    "    num_layers  = 4\n",
    "    dropout     = 0.0\n",
    "    bidirectional = True\n",
    "    logit_dim     = 50\n",
    "    # ========= Training Parameters =========\n",
    "    epochs         = 100\n",
    "    device         = 'cuda'\n",
    "    lr             = 1e-3\n",
    "    batch_size     = 2**9\n",
    "    num_workers    = 64 \n",
    "    sc_name        = 'Robust'\n",
    "    # ======== Early stopping  =============\n",
    "    early_stopping = 5\n",
    "    mode           = 'min'\n",
    "    # ======== Loss Parameters =============\n",
    "    loss_params    = {'name':'MAE_FILTERED'}        \n",
    "    # ======== Optimizer Parameters ========\n",
    "    optimizer_params = {'name':'Adam',\n",
    "                        'WD'  : 0.0}\n",
    "\n",
    "    # ======= Scheduler Parameters =========\n",
    "    # Mode: ['batch','epoch']\n",
    "    scheduler_params = {'name'     : None,\n",
    "                        'step_on'  : None,\n",
    "                        'patience' :  None,\n",
    "                        'step_metric': None}         \n",
    "    # ======= Logging and Saving Parameters ===\n",
    "    project_name    = 'Ventilator-Kaggle'\n",
    "    experiment_name = 'baseline_lstm'\n",
    "    fold            = None\n",
    "    output_dir      = '../03.SavedModels' # Relative to trainer path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "**************** FOLD : 0 *********************\n",
      "***********************************************\n",
      "================= EPOCH: 1 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:42<00:00,  2.76it/s, LR=0.001, Train_Loss=5.98]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.33it/s, Eval_Loss=2.46]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (inf --> 2.4609090089797974). Saving model!\n",
      "================= EPOCH: 2 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:43<00:00,  2.71it/s, LR=0.001, Train_Loss=2.09]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.33it/s, Eval_Loss=2.02]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (2.4609090089797974 --> 2.0151629368464152). Saving model!\n",
      "================= EPOCH: 3 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:42<00:00,  2.75it/s, LR=0.001, Train_Loss=1.53]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:12<00:00,  2.33it/s, Eval_Loss=1.18]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (2.0151629368464152 --> 1.1764485637346904). Saving model!\n",
      "================= EPOCH: 4 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:42<00:00,  2.76it/s, LR=0.001, Train_Loss=1.15]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.09it/s, Eval_Loss=0.974]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (1.1764485637346904 --> 0.9741322894891103). Saving model!\n",
      "================= EPOCH: 5 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:42<00:00,  2.76it/s, LR=0.001, Train_Loss=0.981]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:13<00:00,  2.27it/s, Eval_Loss=0.869]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (0.9741322894891103 --> 0.8691904664039611). Saving model!\n",
      "Didn't meet early stopping\n",
      "Best Val Loss: 0.8691904664039611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:09<00:00,  3.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid Metric:  0.8737820470204125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 99/99 [00:16<00:00,  5.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "***********************************************\n",
      "**************** FOLD : 1 *********************\n",
      "***********************************************\n",
      "================= EPOCH: 1 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:45<00:00,  2.62it/s, LR=0.001, Train_Loss=5.95]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.10it/s, Eval_Loss=2.47]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (inf --> 2.4658446391423543). Saving model!\n",
      "================= EPOCH: 2 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:44<00:00,  2.66it/s, LR=0.001, Train_Loss=2.08]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.11it/s, Eval_Loss=1.82]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (2.4658446391423543 --> 1.81582111120224). Saving model!\n",
      "================= EPOCH: 3 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:44<00:00,  2.66it/s, LR=0.001, Train_Loss=1.5] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:14<00:00,  2.10it/s, Eval_Loss=1.36]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation score improved (1.81582111120224 --> 1.359883721669515). Saving model!\n",
      "================= EPOCH: 4 =================\n",
      "**** Training **** \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 118/118 [00:44<00:00,  2.65it/s, LR=0.001, Train_Loss=1.1] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**** Validation ****\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/30 [00:07<?, ?it/s]\n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-8-5f2a284301f0>\", line 2, in <module>\n",
      "    run_kfold()\n",
      "  File \"<ipython-input-6-94e919434f59>\", line 33, in run_kfold\n",
      "    trainer   = train_fn(train,valid,cfg)\n",
      "  File \"<ipython-input-4-695a06277c97>\", line 6, in train_fn\n",
      "    best_val_loss = trainer.fit(train,valid)\n",
      "  File \"../src/models/trainer.py\", line 107, in fit\n",
      "    valid_loss = self.valid_fn(valid_loader)\n",
      "  File \"../src/models/trainer.py\", line 70, in valid_fn\n",
      "    for b_idx,data in enumerate(tk0):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/tqdm/std.py\", line 1129, in __iter__\n",
      "    for obj in iterable:\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 352, in __iter__\n",
      "    return self._get_iterator()\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 294, in _get_iterator\n",
      "    return _MultiProcessingDataLoaderIter(self)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\", line 801, in __init__\n",
      "    w.start()\n",
      "  File \"/usr/lib/python3.6/multiprocessing/process.py\", line 105, in start\n",
      "    self._popen = self._Popen(self)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 223, in _Popen\n",
      "    return _default_context.get_context().Process._Popen(process_obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/context.py\", line 277, in _Popen\n",
      "    return Popen(process_obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 19, in __init__\n",
      "    self._launch(process_obj)\n",
      "  File \"/usr/lib/python3.6/multiprocessing/popen_fork.py\", line 66, in _launch\n",
      "    self.pid = os.fork()\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py\", line 2044, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 1148, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.6/dist-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1490, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 1448, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 696, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.6/inspect.py\", line 742, in getmodule\n",
      "    os.path.realpath(f)] = module.__name__\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 395, in realpath\n",
      "    path, ok = _joinrealpath(filename[:0], filename, {})\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 429, in _joinrealpath\n",
      "    if not islink(newpath):\n",
      "  File \"/usr/lib/python3.6/posixpath.py\", line 171, in islink\n",
      "    st = os.lstat(path)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    run_kfold()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
